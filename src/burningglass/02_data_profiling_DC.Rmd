---
title: "01_data_profiling"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# load packages 
for (pkg in c("tidyverse", "igraph", "visNetwork", "data.table", "R.utils", "RPostgreSQL", "cowplot", "maditr", "stringr", "stringi", "mosaic", "dplyr", "ggplot2", "lubridate", "readxl")) {
  library(pkg, character.only = TRUE)
}

get_db_conn <-
  function(db_name = "sdad",
           db_host = "postgis1",
           db_port = "5432",
           db_user = Sys.getenv("db_usr"),
           db_pass = Sys.getenv("db_pwd")) {
    RPostgreSQL::dbConnect(
      drv = RPostgreSQL::PostgreSQL(),
      dbname = db_name,
      host = db_host,
      port = db_port,
      user = db_user,
      password = db_pass
    )
  }

con <- get_db_conn()

cert <- DBI::dbGetQuery(con, "
                        SELECT * FROM bgt_res.cert
                        WHERE cert.id in (
                        SELECT ID FROM bgt_res.pers
                        WHERE pers.msa like '%47900%'
                        )"
)

ed <- DBI::dbGetQuery(con, "
                      SELECT * FROM bgt_res.ed
                      WHERE ed.id in (
                      SELECT ID FROM bgt_res.pers
                      WHERE pers.msa like '%47900%'
                      )"
)

job <- DBI::dbGetQuery(con, "
                       SELECT * FROM bgt_res.job
                       WHERE job.id in (
                       SELECT ID FROM bgt_res.pers
                       WHERE pers.msa like '%47900%'
                       )"
)

pers <- DBI::dbGetQuery(con, "
                        SELECT * FROM bgt_res.pers
                        WHERE pers.msa like '%47900%'"
)

DBI::dbDisconnect(con)

```


```{r}
# function for data profiling
data_profiling <- function(df){
  variable_type <- apply(df, 2, function(x) class(x))
  num_unique <- apply(df, 2,  function (x) length(unique(x)))
  num_missing <- apply(df, 2, function(x) sum(is.na(x)))
  perc_missing <- apply(df, 2, function(x) round((sum(is.na(x)))/length(x)* 100, digits = 2))  
  summary_table <- cbind(variable_type, num_unique, num_missing, perc_missing)
  return(summary_table)
}
```


# Table: Cert
In total, there are `r nrow(cert)` entries in cert table. There are two types of certificates: certification and license. On average, each person received 2 certificates (sd = 1.68). 
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
data_profiling(cert)

cert <- cert%>%
  mutate(type = if_else(type == "license", "License", type))

table(cert$type)

cert_n <- cert%>%
  group_by(id)%>%
  summarize(n_cert = n())

ggplot(cert_n, aes(x = n_cert)) + 
  geom_histogram(binwidth = 1.3) + 
  labs(title = "Distribution of the number of certificates people received", x = "number of certificates") 
favstats(cert_n$n_cert)

# top 10 certificates
cert_name <- cert%>%
  group_by(name)%>%
  summarize(n_cert_name = n())%>%
  arrange(desc(n_cert_name))%>%
  top_n(10)%>%
  rename("number of people who received the certificate" = "n_cert_name")
```

# Table: Pers
```{r message = FALSE, warning = FALSE}
data_profiling(pers)

# Preliminary profiling for pers table. 

pers %>% group_by(msa) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

# Checking on MSA. This column is messy and it looks like multiple values are being captured. 

pers %>% group_by(gender) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

# Checking on gender. There are slightly more male than female resumes, but overall pretty even distribution.

pers %>% group_by(zipcode) %>% summarise(n = n()) %>% mutate(freq = n / sum(n)) %>% arrange(-freq) %>% head(15)

# Checking on zip code. The distribution is pretty even. The top 15 are all in the DC metropolitan area. 

pers %>% group_by(noofjobs) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))
ggplot(pers, aes(x = noofjobs)) +
  geom_histogram(bins = 19) +
  labs(title = "number of jobs")

# Checking on the number of jobs. 
```



# Table: Job
```{r message = FALSE, warning = FALSE}
data_profiling(job)

# Preliminary profiling for job table. 

job %>% count(onet) %>% arrange(-n) %>% head(15)

# Checking on onet. There may be some issues with this variable since the number of unique values (1046) is more than the number of unique onet codes online (1016)

year_start <- job %>% mutate(year = year(startdate)) %>% filter(!is.na(year)) %>% group_by(year) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

# Checking on startdate. Some a few observations seem impossible (1900) and some might be unlikely. 

ggplot(year_start, aes(x = year, y = n)) +
  geom_smooth() +
  xlim(2000, 2020) +
  labs(title = "all startdates from 2000 to 2020")

# The distribution of startdates from 2000-2020 looks as expected. 
       
year_end <- job %>% mutate(year = year(enddate)) %>% filter(!is.na(year)) %>% group_by(year) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

ggplot(year_end, aes(x = year, y = n)) +
         geom_smooth() +
         xlim(2000, 2020) +
        labs(title = "all enddates from 2000 to 2020")

# The distribution of enddates is concentrated after 2015. We might expect this since the data is resumes collected from jobseekers around this time.

last_end <- job %>% group_by(id) %>% summarise(last_end = max(enddate)) %>% mutate(year = year(last_end)) %>% filter(!is.na(year)) %>% group_by(year) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

ggplot(last_end, aes(x = year, y = n)) +
          geom_smooth() +
          xlim(2000, 2020) +
          labs(title = "last enddate from 2000 to 2020")
  

# Looking at only the latest enddate for each resume, the observations pick up around 2015, which makes sense with the timing of the collection of the data

job %>% mutate(month = month(startdate)) %>% filter(!is.na(month)) %>% group_by(month) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

job %>% mutate(day = day(startdate)) %>% filter(!is.na(day)) %>% group_by(day) %>% summarise(n = n()) %>% mutate(freq = n / sum(n))

# For month there is a greater frequency of startdates in January. For day the frequency is greatest for the first of the month. 
```


# Table: Ed
In total, there are `r nrow(ed)` entries in ed table.
``` {r message = FALSE, warning = FALSE, paged.print = FALSE}
data_profiling(ed)

#table(ed$degreetype)

degree_clean <- ed%>%
  filter(!is.na(degreetype))%>%
  mutate(degree_somehs = if_else(str_detect(string = degreetype, 
                              pattern = "\\b(?i)(10|11|9)\\b"), T,F))%>%
  mutate(degree_hs = if_else(str_detect(string = degreetype, 
                              pattern = "\\b(?i)(12|High School|ged)\\b"), T,F))%>%
  mutate(degree_bachelor = if_else(str_detect(string = degreetype, 
                              pattern = "\\b(?i)(Bachelor|bachelor|Bachelors|BS|bs|AA|A.A|Undergraduate|undergraduate|postgraduate|Associate|associate)\\b"), T,F))%>%
  mutate(degree_master = if_else(str_detect(string = degreetype, 
                              pattern = "\\b(?i)(master|Master|MBA|M.S|MS|MD)\\b"), T,F))%>%
  mutate(degree_doctor = if_else(str_detect(string = degreetype, 
                              pattern = "\\b(?i)(phd|Ph.D|postdoc)\\b"), T,F))%>%
  mutate(degree_highest = if_else(degree_doctor == T, "doctor", 
                                  if_else(degree_master == T, "master",
                                          if_else(degree_bachelor == T, "bachelor", if_else(degree_hs == T, "hs", 
                                                                                            if_else(degree_somehs == T, "somehs", "others"))))))



table(degree_clean$degree_highest)
```
After a preliminary clean up of degree, we identified `r round((nrow(degree_clean)-267101)/(nrow(degree_clean))* 100, digits = 2) `% of self reported degree type into 5 categories: some high school, high school, bachelor, master, and doctor's degree. 


# Methods for subsetting veterans
```{r message = FALSE, warning = FALSE}
# Reading in KSA crosswalk data
army_ksa_crosswalk <- read_excel("~/git/DSPG2020/career/src/burningglass/army_ksa_crosswalk.xlsx")

# Counting how many resumes are in the DC MSA

job %>% distinct(id) %>% count()

# Counting how many resumes in the DC MSA have a military-specific onet code

military <- "55-[0-9][0-9][0-9][0-9].[0-9][0-9]"

job %>% filter(str_detect(job$onet, military)) %>% distinct(id) %>% count()

military_ids <- job %>% filter(str_detect(job$onet, military)) %>% distinct(id)

# Counting how many resumes in the DC MSA have a onet code in the army crosswalk

job %>% filter(onet %in% army_ksa_crosswalk$`O*NET-SOC Code`) %>% distinct(id) %>% count()

job_ids <- job %>% filter(onet %in% army_ksa_crosswalk$`O*NET-SOC Code`) %>% distinct(id)

# Counting resumes with military education and crosswalk onet

# Just filtering "military" includes some police academies, military high schools
ed %>% filter(grepl("Military", instituition)) %>% count()
ed %>% filter(grepl("Military", instituition)) %>% distinct(instituition) %>% head(10)

# Using a specific school name
institution_ids <- ed %>% filter(grepl("Virginia Military Institute", instituition)) %>% distinct(id)

# Are any veterans captured this way missing from the military-specific method?

instution_job_ids <- inner_join(institution_ids, job_ids)

different_ids <- setdiff(instution_job_ids$id, military_ids$id)

length(different_ids)

```

